{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6: Clustering\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data: check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n",
      "None\n",
      "X    age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
      "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
      "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
      "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
      "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
      "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
      "5   57    1   0       140   192    0        1      148      0      0.4      1   \n",
      "6   56    0   1       140   294    0        0      153      0      1.3      1   \n",
      "7   44    1   1       120   263    0        1      173      0      0.0      2   \n",
      "8   52    1   2       172   199    1        1      162      0      0.5      2   \n",
      "9   57    1   2       150   168    0        1      174      0      1.6      2   \n",
      "\n",
      "   ca  thal  \n",
      "0   0     1  \n",
      "1   0     2  \n",
      "2   0     2  \n",
      "3   0     2  \n",
      "4   0     2  \n",
      "5   0     1  \n",
      "6   0     2  \n",
      "7   0     3  \n",
      "8   0     3  \n",
      "9   0     2  \n",
      "X_norm [[ 0.9521966   0.68100522  1.97312292  0.76395577 -0.25633371  2.394438\n",
      "  -1.00583187  0.01544279 -0.69663055  1.08733806 -2.27457861 -0.71442887\n",
      "  -2.14887271]\n",
      " [-1.91531289  0.68100522  1.00257707 -0.09273778  0.07219949 -0.41763453\n",
      "   0.89896224  1.63347147 -0.69663055  2.12257273 -2.27457861 -0.71442887\n",
      "  -0.51292188]\n",
      " [-1.47415758 -1.46841752  0.03203122 -0.09273778 -0.81677269 -0.41763453\n",
      "  -1.00583187  0.97751389 -0.69663055  0.31091206  0.97635214 -0.71442887\n",
      "  -0.51292188]\n",
      " [ 0.18017482  0.68100522  0.03203122 -0.66386682 -0.19835726 -0.41763453\n",
      "   0.89896224  1.23989692 -0.69663055 -0.20670527  0.97635214 -0.71442887\n",
      "  -0.51292188]\n",
      " [ 0.29046364 -1.46841752 -0.93851463 -0.66386682  2.08204965 -0.41763453\n",
      "   0.89896224  0.58393935  1.43548113 -0.37924438  0.97635214 -0.71442887\n",
      "  -0.51292188]\n",
      " [ 0.29046364  0.68100522 -0.93851463  0.47839125 -1.04867848 -0.41763453\n",
      "   0.89896224 -0.07201822 -0.69663055 -0.55178349 -0.64911323 -0.71442887\n",
      "  -2.14887271]\n",
      " [ 0.18017482 -1.46841752  0.03203122  0.47839125  0.92252071 -0.41763453\n",
      "  -1.00583187  0.1466343  -0.69663055  0.22464251 -0.64911323 -0.71442887\n",
      "  -0.51292188]\n",
      " [-1.1432911   0.68100522  0.03203122 -0.66386682  0.32343076 -0.41763453\n",
      "   0.89896224  1.0212444  -0.69663055 -0.89686172  0.97635214 -0.71442887\n",
      "   1.12302895]\n",
      " [-0.26098049  0.68100522  1.00257707  2.30600417 -0.91340011  2.394438\n",
      "   0.89896224  0.54020884 -0.69663055 -0.46551394  0.97635214 -0.71442887\n",
      "   1.12302895]\n",
      " [ 0.29046364  0.68100522  1.00257707  1.04952029 -1.51249006 -0.41763453\n",
      "   0.89896224  1.0649749  -0.69663055  0.48345117  0.97635214 -0.71442887\n",
      "  -0.51292188]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "\n",
    "heartData = pd.read_csv(\"D:\\Programming\\Python_code\\PrinciplesOfDS_Course\\Labs\\Data\\heart.csv\")\n",
    "print(heartData.info()) # all data types int or float, no non-numeric features. No categorical features to convert \n",
    "\n",
    "# Check for missing values \n",
    "heartData.isna().sum()/heartData.shape[0] # all values 0. No missing values. \n",
    "\n",
    "X, y = heartData.drop(columns='target'), heartData.target\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_norm = normalizer.fit_transform(X)\n",
    "print(\"X\", X.iloc[:10,])\n",
    "print('X_norm',X_norm[:10,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The normalized mutual information score of the K-means method is 0.3234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tanner_N\\AppData\\Local\\Python\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# no point in doing more than 2 clusters as we know there are only 2 possible categories already\n",
    "cluster = KMeans(n_clusters=2, random_state=1).fit(X_norm) \n",
    "\n",
    "nmi = normalized_mutual_info_score(cluster.labels_, y, average_method='arithmetic')\n",
    "print('The normalized mutual information score of the K-means method is {:.4f}'.format(nmi))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try different hyper-parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32341194603576945\n",
      "0.3234119460357694\n",
      "0.3234119460357694\n",
      "0.32341194603576945\n",
      "0.32967483885081544\n",
      "0.32967483885081544\n",
      "0.3234119460357694\n",
      "0.3296748388508154\n",
      "0.2749021353467294\n",
      "0.25373964228288276\n",
      "0.2749021353467294\n",
      "0.2749021353467294\n",
      "0.27136707411437866\n",
      "0.2749021353467294\n",
      "0.2749021353467294\n",
      "0.2749021353467294\n",
      "0.19537049518825259\n",
      "0.2030474974165272\n",
      "0.20093935290612572\n",
      "0.20624278848512545\n",
      "0.20486584603827884\n",
      "0.21188736682468978\n",
      "0.20624278848512545\n",
      "0.19688080257753196\n",
      "0.19580947694841144\n",
      "0.19514005531513862\n",
      "0.1989861459774026\n",
      "0.195209873123672\n",
      "0.1950388717106049\n",
      "0.18810542151947232\n",
      "0.197761964850533\n",
      "0.1968382531471918\n",
      "Best of each category:\n",
      "Best nmi 0.32967483885081544\n",
      "Best k cluster 2\n",
      "Best n_init 30\n",
      "Best init k-means++\n"
     ]
    }
   ],
   "source": [
    "test_k = [2,3,4,5]\n",
    "test_n_init = [10, 20, 30, 50]\n",
    "test_init = ['k-means++', 'random']\n",
    "\n",
    "best_nmi = 0\n",
    "best_k = None\n",
    "best_n_init = None\n",
    "best_init = None\n",
    "\n",
    "for k in test_k:\n",
    "    for n in test_n_init:\n",
    "        for init in test_init:\n",
    "            temp_cluster = KMeans(n_clusters=k, init=init, n_init=n).fit(X_norm)\n",
    "            temp_nmi = normalized_mutual_info_score(temp_cluster.labels_, y, average_method='arithmetic')\n",
    "            print(temp_nmi)\n",
    "            if(temp_nmi > best_nmi):\n",
    "                best_nmi = temp_nmi\n",
    "                best_k = k\n",
    "                best_n_init = n\n",
    "                best_init = init\n",
    "\n",
    "print(\"Best of each category:\\nBest nmi {}\\nBest k cluster {}\\nBest n_init {}\\nBest init {}\".format(best_nmi, best_k, best_n_init, best_init))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thoughts on different parameters: \n",
    "As stated above, there really isnt a point in trying to use more than 2 clusters, as we only have 2 possible categories of data. We know this going in, so we know the optimal cluster amount going in. Results substantially change for the worse with greater cluster amounts, further, there is no real imrovement on the nmi score in testing other hyperparameters. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agglomerative Clustering:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The normalized mutual information score of the Agglomerative clustering method is 0.0111\n"
     ]
    }
   ],
   "source": [
    "agg_cluster = AgglomerativeClustering(n_clusters=2).fit(X)\n",
    "\n",
    "nmi = normalized_mutual_info_score(agg_cluster.labels_, y, average_method='arithmetic')\n",
    "print('The normalized mutual information score of the Agglomerative clustering method is {:.4f}'.format(nmi))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test different hyperparameters: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011063515436362354\n",
      "0.00027129245492457866\n",
      "0.00027129245492457866\n",
      "0.005652750492624307\n",
      "0.009001669557496405\n",
      "0.03393886998938809\n",
      "0.005272370527725735\n",
      "0.012547879744986242\n",
      "0.009229764064007892\n",
      "0.036507355506030355\n",
      "0.02674253534651711\n",
      "0.01749723859550799\n",
      "0.01326847734067055\n",
      "0.04322159014456702\n",
      "0.030500596599103175\n",
      "0.016133747429041743\n",
      "0.02871304161117195\n",
      "0.06274143379776896\n",
      "0.03129531303084799\n",
      "0.021841921862053443\n",
      "0.03690019438473182\n",
      "0.06378177909188953\n",
      "0.0414857169831583\n",
      "0.025893914500633223\n",
      "0.036909483511863635\n",
      "0.05676875387176104\n",
      "0.051571308995400744\n",
      "0.026296269762886657\n",
      "0.03828095912038763\n",
      "0.0605508197088417\n",
      "0.050286051160642456\n",
      "0.031208774165090748\n",
      "0.03866165426109681\n",
      "0.060131912673690044\n",
      "0.051291767771655096\n",
      "0.03592698315155799\n",
      "Best nmi 0.0638\n",
      "Best setting complete\n",
      "Best n_clusters 7\n"
     ]
    }
   ],
   "source": [
    "n_clusters = [2,3,4,5,6,7,8,9,10]\n",
    "linkage_setting = ['ward','complete','average','single']\n",
    "\n",
    "best_agg_nmi = 0\n",
    "best_setting = None\n",
    "best_n_clusters = 0\n",
    "for n in n_clusters:\n",
    "    for s in linkage_setting:\n",
    "        agg_cluster_temp = AgglomerativeClustering(n_clusters=n, linkage=s).fit(X)\n",
    "        temp_nmi = normalized_mutual_info_score(agg_cluster_temp.labels_, y, average_method='arithmetic')\n",
    "        print(temp_nmi)\n",
    "        if(temp_nmi > best_agg_nmi):\n",
    "            best_agg_nmi = temp_nmi\n",
    "            best_setting = s\n",
    "            best_n_clusters = n\n",
    "\n",
    "print(\"Best nmi {:.4f}\\nBest setting {}\\nBest n_clusters {}\".format(best_agg_nmi,best_setting, best_n_clusters))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion: \n",
    "While it appears like 7 clusters performs better than lower numbers of them for the agglomerative clustering method, I don't think this is because there actually exist 7 distinct clusters in our data. The fact that at best we achieve a .06 NMI score also implies there is very little correlation between the clusters found and the base data. This score is substantially worse than the best score found for KMeans clustering, with ~.33 NMI. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6fa2c8eb31e883fb5a22fbf67621de023b5dc228d46f0c7fcdad9efff2c48063"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
